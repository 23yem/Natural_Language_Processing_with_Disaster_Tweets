{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to my first NLP Competition! This is my first notebook attempt for the NLP with Disaster Tweets (Kaggle) Competition!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: pip install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy tensorflow transformers scikit-learn matplotlib\n",
    "\n",
    "# #python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploring and Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "I had a hard choice of whether or not to delete hashtags, but after inspecting the data, I saw that there were so many hashtags and hashtags are a crucial part of tweets so I decided that I want to keep them and then do the extra work of preprecessing them later on when I preprocess the data.\n",
    "\n",
    "I might go and remove hashtags in the future, to see how it affects the performance. So, if you see that I decided to remove the hashtags, then now you know why!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Our Deeds are the Reason of this #earthquake M...   \n",
      "1             Forest fire near La Ronge Sask. Canada   \n",
      "2  All residents asked to 'shelter in place' are ...   \n",
      "3  13,000 people receive #wildfires evacuation or...   \n",
      "4  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  our deeds are the reason of this #earthquake m...  \n",
      "1              forest fire near la ronge sask canada  \n",
      "2  all residents asked to shelter in place are be...  \n",
      "3   people receive #wildfires evacuation orders i...  \n",
      "4  just got sent this photo from ruby #alaska as ...  \n"
     ]
    }
   ],
   "source": [
    "import re # Regular Expression\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)     # Remove mentions\n",
    "    text = re.sub(r'\\d+', '', text)      # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s#]', '', text)  # Remove punctuation except hashtags\n",
    "    text = text.lower()                  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "train_data['clean_text'] = train_data['text'].apply(clean_text) # Apply the data cleaning process to training data\n",
    "test_data['clean_text'] = test_data['text'].apply(clean_text)# Apply the data cleaning process to testing data\n",
    "\n",
    "# Display the first few rows of the cleaned data\n",
    "print(train_data[['text', 'clean_text']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization from bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Tweet: [101, 2045, 2003, 1037, 7071, 6230, 102]\n",
      "                                          clean_text  \\\n",
      "0  our deeds are the reason of this #earthquake m...   \n",
      "1              forest fire near la ronge sask canada   \n",
      "2  all residents asked to shelter in place are be...   \n",
      "3   people receive #wildfires evacuation orders i...   \n",
      "4  just got sent this photo from ruby #alaska as ...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [101, 2256, 15616, 2024, 1996, 3114, 1997, 202...  \n",
      "1  [101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...  \n",
      "2  [101, 2035, 3901, 2356, 2000, 7713, 1999, 2173...  \n",
      "3  [101, 2111, 4374, 1001, 3748, 26332, 13982, 44...  \n",
      "4  [101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...  \n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example raw tweet\n",
    "tweet = \"There is a disaster happening\"\n",
    "\n",
    "# Tokenize the tweet\n",
    "tokenized_tweet = tokenizer.encode(tweet, add_special_tokens=True)\n",
    "print(\"Tokenized Tweet:\", tokenized_tweet)\n",
    "\n",
    "# Tokenize the clean text including hashtags\n",
    "train_data['tokens'] = train_data['clean_text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "test_data['tokens'] = test_data['clean_text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "\n",
    "# Display the first few tokenized texts\n",
    "print(train_data[['clean_text', 'tokens']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the length of tokens to find the optimal maximum length for sequences\n",
    "\n",
    "Based on the results from this, we saw that the maximum sequence length (a sequence in this context is a single tweet) was around 40, and so we will pick a multiple of 2 for better computational performance. \n",
    "\n",
    "So, I decided on 64!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train token length statistics:\n",
      "count    7613.000000\n",
      "mean       18.689741\n",
      "std         7.073642\n",
      "min         3.000000\n",
      "25%        13.000000\n",
      "50%        19.000000\n",
      "75%        24.000000\n",
      "max        43.000000\n",
      "Name: token_length, dtype: float64\n",
      "\n",
      "Test token length statistics:\n",
      "count    3263.000000\n",
      "mean       18.774441\n",
      "std         7.170217\n",
      "min         3.000000\n",
      "25%        13.000000\n",
      "50%        19.000000\n",
      "75%        24.000000\n",
      "max        42.000000\n",
      "Name: token_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tokenize the clean text without padding to get the length of each tweet\n",
    "train_data['token_length'] = train_data['clean_text'].apply(lambda x: len(tokenizer.encode(x, add_special_tokens=True)))\n",
    "test_data['token_length'] = test_data['clean_text'].apply(lambda x: len(tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "# Plot the distribution of token lengths\n",
    "plt.hist(train_data['token_length'], bins=50, alpha=0.7, label='Train')\n",
    "plt.hist(test_data['token_length'], bins=50, alpha=0.7, label='Test')\n",
    "plt.axvline(x=128, color='r', linestyle='--', label='MAX_LEN = 128')\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Display some statistics\n",
    "print(\"Train token length statistics:\")\n",
    "print(train_data['token_length'].describe())\n",
    "\n",
    "print(\"\\nTest token length statistics:\")\n",
    "print(test_data['token_length'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding and Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tokens  \\\n",
      "0  [101, 2256, 15616, 2024, 1996, 3114, 1997, 202...   \n",
      "1  [101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...   \n",
      "2  [101, 2035, 3901, 2356, 2000, 7713, 1999, 2173...   \n",
      "3  [101, 2111, 4374, 1001, 3748, 26332, 13982, 44...   \n",
      "4  [101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...   \n",
      "\n",
      "                                       padded_tokens  \n",
      "0  [101, 2256, 15616, 2024, 1996, 3114, 1997, 202...  \n",
      "1  [101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...  \n",
      "2  [101, 2035, 3901, 2356, 2000, 7713, 1999, 2173...  \n",
      "3  [101, 2111, 4374, 1001, 3748, 26332, 13982, 44...  \n",
      "4  [101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...  \n"
     ]
    }
   ],
   "source": [
    "# Define the custom maximum length for the sequences based on analysis\n",
    "MAX_LEN = 64\n",
    "\n",
    "# Pad the token sequences and truncate longer sequences\n",
    "padded_train_tokens = pad_sequences(train_data['tokens'].tolist(), maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "padded_test_tokens = pad_sequences(test_data['tokens'].tolist(), maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Convert the 2D arrays to lists of lists\n",
    "train_data['padded_tokens'] = list(padded_train_tokens)\n",
    "test_data['padded_tokens'] = list(padded_test_tokens)\n",
    "\n",
    "# Display the first few tokenized and padded sequences\n",
    "print(train_data[['tokens', 'padded_tokens']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Building a model!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking a Model Architecture\n",
    "\n",
    "I am going to pick BERT but I might play around with other pretrained models later. \n",
    "\n",
    "This is an example of transfer learning, where I am taking a pretrained model (ex. BERT) and then training it on my specific data. No need to re-invent the wheel, especially since it will take long time to make a model from scratch and I might not get great results back since my training data size is not very good. The BERT model is training on SO MUCH data, so it's already very smart.\n",
    "\n",
    "I am using the BERT model and by doing import TFBertForSequenceClassification, I am using the model that adds a classification head to the BERT base model. Adding a layer to a pre-trained model is a crucial part of transfer learning, and by training the model on my data, I will be setting the weights of the new head layer of the model, which is where it learns about disaster tweets and how to classify them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2) # num_labels = 2 since this is a binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=3e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data['padded_tokens'], train_data['target'], test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.tolist(), y_train.tolist())).shuffle(len(X_train)).batch(32)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val.tolist(), y_val.tolist())).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1588, in compute_loss  *\n        return super().compute_loss(*args, **kwargs)\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss  **\n        return self.compiled_loss(\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 275, in __call__\n        y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 854, in match_dtype_and_rank\n        if (y_t.dtype.is_floating and y_p.dtype.is_floating) or (\n\n    AttributeError: 'NoneType' object has no attribute 'dtype'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileet3zuto3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1706\u001b[0m, in \u001b[0;36mTFPreTrainedModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1703\u001b[0m             y_pred \u001b[38;5;241m=\u001b[39m y_pred[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1706\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m   1709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables, tape\u001b[38;5;241m=\u001b[39mtape)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file4p2rvgr5.py:38\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__compute_loss\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompute_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file4p2rvgr5.py:24\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__compute_loss.<locals>.if_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28msuper\u001b[39m), (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\u001b[38;5;241m.\u001b[39mcompute_loss, \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1588, in compute_loss  *\n        return super().compute_loss(*args, **kwargs)\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss  **\n        return self.compiled_loss(\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 275, in __call__\n        y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n    File \"c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 854, in match_dtype_and_rank\n        if (y_t.dtype.is_floating and y_p.dtype.is_floating) or (\n\n    AttributeError: 'NoneType' object has no attribute 'dtype'\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=3, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluating and Submitting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_data['padded_tokens'].tolist()).batch(32)\n",
    "predictions = model.predict(test_dataset).logits\n",
    "predictions = tf.nn.softmax(predictions, axis=1)\n",
    "predicted_labels = tf.argmax(predictions, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Submission File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_data['id'], 'target': predicted_labels})\n",
    "submission.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Iterating and Improving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning:\n",
    "- Experiment with different hyperparameters such as learning rate, batch size, and the number of epochs to improve the models performance.\n",
    "\n",
    "Data Augmentation:\n",
    "- Consider using data augmentation techniques to increase the diversity of your training data.\n",
    "\n",
    "Model Ensembles:\n",
    "- Combine the predictions from multiple models to improve overall performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
